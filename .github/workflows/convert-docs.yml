name: Convert Documentation

on:
  push:
    branches: [ main ]
    paths:
      - 'components/**/Eco.Core1_EN.fodt'  # for tests purpose one file only
  workflow_dispatch:  # Allow manual triggering

jobs:
  convert-and-sync:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # For source repo
      id-token: write  # For GitHub App token

    steps:
    - name: Checkout source
      uses: actions/checkout@v4
      with:
        fetch-depth: 2  # Needed for git diff

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'

    - name: Cache APT packages
      uses: actions/cache@v3
      with:
        path: |
          /var/cache/apt/archives
          /var/lib/apt/lists
        key: ${{ runner.os }}-apt-${{ hashFiles('**/convert-docs.yml') }}
        restore-keys: |
          ${{ runner.os }}-apt-

    - name: Cache Python packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/convert-docs.yml') }}
        restore-keys: |
          ${{ runner.os }}-pip-



    - name: Install LibreOffice and extension
      id: install-libreoffice
      run: |
        echo "=== LIBREOFFICE INSTALLATION START ==="
        echo "📦 Updating package lists..."
        if sudo apt-get update; then
          echo "✅ Package lists updated successfully"
        else
          echo "❌ Failed to update package lists"
          exit 1
        fi
        
        echo "📦 Installing LibreOffice..."
        if sudo apt-get install libreoffice -y; then
          echo "✅ LibreOffice installed successfully"
        else
          echo "❌ Failed to install LibreOffice"
          exit 1
        fi
        
        echo "🐍 Installing Python dependencies..."
        if pip install frontmatter; then
          echo "✅ Python frontmatter package installed"
        else
          echo "❌ Failed to install frontmatter package"
          exit 1
        fi
        
        # Install the DocExport extension using unopkg for current user
        echo "🔧 Installing DocExport extension..."
        if [ -f ".github/workflows/DocExport.oxt" ]; then
          echo "✅ DocExport.oxt file found"
          echo "📊 Extension file size: $(stat -c%s .github/workflows/DocExport.oxt) bytes"
          
          if unopkg add .github/workflows/DocExport.oxt; then
            echo "✅ Extension installation completed successfully"
            echo "🔍 Listing installed extensions:"
            unopkg list --user 2>/dev/null || echo "Cannot list extensions"
          else
            echo "❌ Extension installation failed"
            echo "🔍 Checking unopkg availability:"
            which unopkg || echo "unopkg not found in PATH"
            exit 1
          fi
        else
          echo "❌ ERROR: DocExport.oxt not found!"
          echo "🔍 Contents of .github/workflows directory:"
          ls -la .github/workflows/ || echo "Directory not accessible"
          exit 1
        fi
        
        # Verify LibreOffice is working
        echo "🔍 Verifying LibreOffice installation..."
        if soffice --version; then
          echo "✅ LibreOffice verification successful"
        else
          echo "❌ LibreOffice verification failed"
          exit 1
        fi
        echo "=== LIBREOFFICE INSTALLATION COMPLETE ==="

    - name: Load Conversion State
      id: load-state
      run: |
        echo "=== LOADING CONVERSION STATE ==="
        
        # Clone target repo to check for existing state
        mkdir -p ~/.ssh
        ssh-keyscan -t ed25519,rsa github.com >> ~/.ssh/known_hosts
        eval "$(ssh-agent -s)"
        ssh-add - <<< "${{ secrets.VITEPRESS_DEPLOY_TOKEN }}"
        
        if git clone git@github.com:peerf-eco/docs-vitepress.git state-check; then
          echo "✅ Target repository cloned for state check"
          
          if [ -f "state-check/.conversion-state.json" ]; then
            echo "📄 Found existing conversion state"
            cp state-check/.conversion-state.json ./current-state.json
            
            file_size=$(stat -c%s ./current-state.json 2>/dev/null || echo '0')
            echo "📊 State file size: $file_size bytes"
            
            # Validate state file is not empty or corrupted
            if [ "$file_size" -eq 0 ]; then
              echo "⚠️  State file is empty, creating fresh state"
              echo '{}' > ./current-state.json
              LAST_COMMIT=""
            else
              # Extract last processed commit with error handling
              LAST_COMMIT=$(python3 -c "
try:
    import json
    with open('current-state.json') as f:
        state = json.load(f)
    print(state.get('lastProcessedCommit', ''))
except (json.JSONDecodeError, FileNotFoundError, KeyError) as e:
    print('', end='')
" 2>/dev/null || echo "")
              
              # Validate state file structure
              if ! python3 -c "import json; json.load(open('current-state.json'))" 2>/dev/null; then
                echo "⚠️  State file is corrupted, creating fresh state"
                echo '{}' > ./current-state.json
                LAST_COMMIT=""
              else
                echo "✅ State file validated successfully"
              fi
            fi
            
            echo "🔍 Last processed commit: ${LAST_COMMIT:-'none'}"
            echo "LAST_PROCESSED_COMMIT=${LAST_COMMIT}" >> $GITHUB_ENV
            
            # Show current state summary
            python3 -c "
try:
    import json
    with open('current-state.json') as f:
        state = json.load(f)
    failed_count = len(state.get('failedFiles', {}))
    if failed_count > 0:
        print(f'Found {failed_count} previously failed files that will be retried')
        for file_path, details in state.get('failedFiles', {}).items():
            attempt_count = details.get('attemptCount', 0)
            print(f'  - {file_path} (attempt #{attempt_count + 1})')
except:
    pass
" 2>/dev/null
          else
            echo "ℹ️  No existing state found, creating initial state"
            echo '{}' > ./current-state.json
            echo "LAST_PROCESSED_COMMIT=" >> $GITHUB_ENV
          fi
        else
          echo "❌ Failed to clone target repository for state check"
          exit 1
        fi
        
        rm -rf state-check
        echo "=== STATE LOADING COMPLETE ==="

    - name: Debug Git State
      id: debug-git
      run: |
        echo "=== GIT STATE DEBUG ==="
        echo "Current commit (HEAD): $(git rev-parse HEAD)"
        echo "Previous commit (HEAD~1): $(git rev-parse HEAD~1 2>/dev/null || echo 'N/A - single commit')"
        echo "Last processed commit: ${LAST_PROCESSED_COMMIT:-'none'}"
        echo "Fetch depth used: 2"
        echo "Git log (last 3 commits):"
        git log --oneline -3 || echo "Less than 3 commits available"
        echo "Files in components directory:"
        find components -name "*.fodt" -type f | head -10 || echo "No .fodt files found"
        echo "=== END GIT STATE DEBUG ==="

    - name: Find changed files
      id: changed-files
      run: |
        echo "=== STATE-BASED CHANGE DETECTION ==="
        
        if [ -n "${LAST_PROCESSED_COMMIT}" ]; then
          echo "🔍 Using state-based detection from commit: ${LAST_PROCESSED_COMMIT}"
          
          # Verify the commit exists
          if git rev-parse --verify "${LAST_PROCESSED_COMMIT}" >/dev/null 2>&1; then
            CHANGED_FILES=$(git diff --name-only ${LAST_PROCESSED_COMMIT}..HEAD -- 'components/**/*.fodt' 2>/dev/null || echo "")
            echo "✅ Successfully compared against last processed commit"
          else
            echo "⚠️  Last processed commit ${LAST_PROCESSED_COMMIT} not found, falling back to HEAD~1"
            CHANGED_FILES=$(git diff --name-only HEAD~1..HEAD -- 'components/**/*.fodt' 2>/dev/null || echo "")
          fi
        else
          echo "🔍 No previous state, using HEAD~1 comparison"
          
          # Handle single commit repository
          if git rev-parse --verify HEAD~1 >/dev/null 2>&1; then
            CHANGED_FILES=$(git diff --name-only HEAD~1..HEAD -- 'components/**/*.fodt' 2>/dev/null || echo "")
          else
            echo "ℹ️  Single commit repository, checking all .fodt files"
            CHANGED_FILES=$(find components -name "*.fodt" -type f 2>/dev/null | head -20 || echo "")
          fi
        fi
        
        echo "📊 Changed files found: $(echo "$CHANGED_FILES" | wc -w)"
        
        # Check for failed files from previous runs (with retry limit)
        FAILED_FILES=$(python3 -c "
import json
try:
    with open('current-state.json') as f:
        state = json.load(f)
    failed = state.get('failedFiles', {})
    # Only include files that haven't exceeded retry limit (max 3 attempts)
    retry_files = []
    max_retries = 3
    for file_path, details in failed.items():
        attempt_count = details.get('attemptCount', 0)
        if attempt_count < max_retries:
            retry_files.append(file_path)
        else:
            print(f'Skipping {file_path} - exceeded max retries ({attempt_count}/{max_retries})', file=__import__('sys').stderr)
    print(' '.join(retry_files))
except Exception as e:
    pass
" 2>/dev/null || echo "")
        
        failed_count=$(echo "$FAILED_FILES" | wc -w)
        if [ $failed_count -gt 0 ]; then
          echo "🔄 Including $failed_count previously failed files for retry (within retry limit)"
        fi
        
        # Combine changed and failed files
        ALL_FILES="${CHANGED_FILES} ${FAILED_FILES}"
        ALL_FILES=$(echo $ALL_FILES | tr ' ' '\n' | sort -u | tr '\n' ' ' | sed 's/ $//')
        
        if [ -n "$ALL_FILES" ]; then
          echo "any_changed=true" >> $GITHUB_OUTPUT
          echo "all_changed_files=$ALL_FILES" >> $GITHUB_OUTPUT
          echo "✅ Files to process: $ALL_FILES"
        else
          echo "any_changed=false" >> $GITHUB_OUTPUT
          echo "all_changed_files=" >> $GITHUB_OUTPUT
          echo "ℹ️  No files to process"
        fi
        
        echo "=== END STATE-BASED CHANGE DETECTION ==="

    - name: Process Change Detection Results
      run: |
        echo "=== CHANGE DETECTION RESULTS ==="
        echo "Any files changed: ${{ steps.changed-files.outputs.any_changed }}"
        echo "Files added: ${{ steps.changed-files.outputs.added_files }}"
        echo "Files modified: ${{ steps.changed-files.outputs.modified_files }}"
        echo "Files deleted: ${{ steps.changed-files.outputs.deleted_files }}"
        echo "All changed files: ${{ steps.changed-files.outputs.all_changed_files }}"
        
        if [ "${{ steps.changed-files.outputs.any_changed }}" == "true" ]; then
          file_count=$(echo '${{ steps.changed-files.outputs.all_changed_files }}' | wc -w)
          echo "✅ CHANGES DETECTED: $file_count file(s) to process"
          
          # Check for deleted files
          deleted_files="${{ steps.changed-files.outputs.deleted_files }}"
          if [ -n "$deleted_files" ]; then
            echo "⚠️  DELETED FILES DETECTED: $deleted_files"
            echo "Note: Deleted files cannot be converted but may need cleanup in target repo"
          fi
          
          echo "Files to convert:"
          processable_files=0
          for file in ${{ steps.changed-files.outputs.all_changed_files }}; do
            echo "  - $file"
            if [ -f "$file" ]; then
              file_size=$(stat -c%s "$file" 2>/dev/null || echo '0')
              echo "    ✅ File exists and is readable"
              echo "    📊 File size: $file_size bytes"
              
              if [ "$file_size" -eq 0 ]; then
                echo "    ⚠️  WARNING: File is empty (0 bytes)"
              elif [ "$file_size" -lt 100 ]; then
                echo "    ⚠️  WARNING: File is very small ($file_size bytes) - may be incomplete"
              fi
              processable_files=$((processable_files + 1))
            else
              echo "    ❌ WARNING: File not found or not readable (likely deleted)"
            fi
          done
          
          echo "📊 Summary: $processable_files processable files out of $file_count total changes"
        else
          echo "ℹ️  NO CHANGES DETECTED"
          echo "Reason: No .fodt files in components/** have been modified since the last commit"
          echo "This is normal behavior - the workflow will skip conversion steps"
          
          # Additional debugging for no-changes scenario
          echo "🔍 Additional debugging information:"
          echo "  - Current workflow path filter: components/**/*.fodt"
          echo "  - Actual path filter used: ${{ steps.changed-files.outputs.files }}"
          echo "  - Comparison: HEAD vs HEAD~1"
          echo "  - Repository has $(git rev-list --count HEAD) total commits"
        fi
        echo "=== END CHANGE DETECTION RESULTS ==="

    - name: No Changes Detected
      if: steps.changed-files.outputs.any_changed != 'true'
      run: |
        echo "=== NO CONVERSION NEEDED ==="
        echo "ℹ️  WORKFLOW RESULT: No changes detected"
        echo ""
        echo "This means:"
        echo "  • No .fodt files in components/** have been modified since the last commit"
        echo "  • The workflow is working correctly by skipping unnecessary conversions"
        echo "  • No files will be converted or pushed to the target repository"
        echo ""
        echo "If you expected changes to be detected:"
        echo "  1. Verify your .fodt files are in the components/ directory"
        echo "  2. Check that files were actually modified in the last commit"
        echo "  3. Ensure the workflow path filter matches your file locations"
        echo ""
        echo "Current workflow path filter: components/**/*.fodt"
        echo "=== WORKFLOW COMPLETE (NO ACTION REQUIRED) ==="

    - name: Convert to Markdown
      id: convert
      if: steps.changed-files.outputs.any_changed == 'true'
      run: |
        echo "=== CONVERSION START ==="
        file_count=$(echo '${{ steps.changed-files.outputs.all_changed_files }}' | wc -w)
        echo "🔄 Starting conversion of $file_count file(s)"
        echo "Files to convert: ${{ steps.changed-files.outputs.all_changed_files }}"
        
        # Export GitHub environment variables for the script
        echo "GITHUB_SERVER_URL=${{ github.server_url }}" >> $GITHUB_ENV
        echo "GITHUB_REPOSITORY=${{ github.repository }}" >> $GITHUB_ENV
        echo "GITHUB_SHA=${{ github.sha }}" >> $GITHUB_ENV
        
        # Create converted_docs directory and list contents before conversion
        mkdir -p converted_docs
        echo "Contents before conversion:"
        ls -la converted_docs/ || echo "Directory is empty"
        
        # Call the new extension-based conversion script with changed files as arguments
        echo "🚀 Executing conversion script..."
        
        # Track files for state management
        PROCESSED_FILES=""
        FAILED_FILES=""
        
        for file in ${{ steps.changed-files.outputs.all_changed_files }}; do
          if [ -f "$file" ]; then
            echo "🔄 Processing: $file"
            if bash .github/workflows/convert_docs_extension.sh "$file"; then
              echo "✅ Successfully converted: $file"
              PROCESSED_FILES="$PROCESSED_FILES $file"
            else
              echo "❌ Failed to convert: $file"
              FAILED_FILES="$FAILED_FILES $file"
            fi
          else
            echo "⚠️  Skipping non-existent file: $file"
          fi
        done
        
        # Export for state tracking
        echo "PROCESSED_FILES=$PROCESSED_FILES" >> $GITHUB_ENV
        echo "FAILED_FILES=$FAILED_FILES" >> $GITHUB_ENV
        
        # Overall status
        if [ -n "$FAILED_FILES" ]; then
          echo "⚠️  Some files failed conversion but continuing with successful ones"
        fi
        
        if [ -z "$PROCESSED_FILES" ]; then
          echo "❌ No files were successfully converted"
          exit 1
        fi
        
        echo "✅ Conversion completed with $(echo $PROCESSED_FILES | wc -w) successful files"
        
    - name: Verify Conversion Results
      if: steps.changed-files.outputs.any_changed == 'true'
      run: |
        echo "=== CONVERSION VERIFICATION ==="
        
        if [ -d "converted_docs" ]; then
          echo "📁 Converted docs directory contents:"
          ls -la converted_docs/
          
          md_count=$(find converted_docs -name "*.md" | wc -l)
          echo "📄 Total .md files created: $md_count"
          
          if [ $md_count -gt 0 ]; then
            echo "✅ Conversion successful - found $md_count markdown file(s)"
            echo "📋 Generated files:"
            find converted_docs -name "*.md" -exec basename {} \; | sort
            
            echo "📊 File sizes:"
            find converted_docs -name "*.md" -exec ls -lh {} \; | awk '{print "  " $9 ": " $5}'
          else
            echo "⚠️  WARNING: No markdown files were created"
            echo "🔍 Checking for other file types:"
            find converted_docs -type f | head -10
          fi
        else
          echo "❌ ERROR: converted_docs directory not found"
          echo "🔍 Current directory contents:"
          ls -la
          exit 1
        fi
        echo "=== END CONVERSION VERIFICATION ==="

    - name: Clone, copy files, and push to docs repo
      id: deploy
      if: steps.changed-files.outputs.any_changed == 'true'
      env:
        TARGET_REPO_SSH_KEY: ${{ secrets.VITEPRESS_DEPLOY_TOKEN }}
      shell: bash
      run: |
        set -euo pipefail
        echo "=== DEPLOYMENT TO TARGET REPOSITORY START ==="
        echo "🎯 Target repository: peerf-eco/docs-vitepress"
        echo "📂 Source directory: converted_docs/"
        echo "📂 Target directory: docs/components/"
        
        # Setup SSH
        echo "🔐 Setting up SSH authentication..."
        if mkdir -p ~/.ssh; then
          echo "✅ SSH directory created"
        else
          echo "❌ Failed to create SSH directory"
          exit 1
        fi
        
        echo "🔑 Adding GitHub to known hosts..."
        if ssh-keyscan -t ed25519,rsa github.com >> ~/.ssh/known_hosts; then
          echo "✅ GitHub added to known hosts"
        else
          echo "❌ Failed to add GitHub to known hosts"
          exit 1
        fi
        
        echo "🔑 Starting SSH agent..."
        if eval "$(ssh-agent -s)"; then
          echo "✅ SSH agent started"
        else
          echo "❌ Failed to start SSH agent"
          exit 1
        fi
        
        echo "🔑 Adding SSH key..."
        if ssh-add - <<< "$TARGET_REPO_SSH_KEY"; then
          echo "✅ SSH key added successfully"
        else
          echo "❌ Failed to add SSH key"
          echo "🔍 SSH key length: ${#TARGET_REPO_SSH_KEY} characters"
          exit 1
        fi
        
        # Clone and copy files
        echo "💾 Cloning target repository..."
        if git clone git@github.com:peerf-eco/docs-vitepress.git docs-vitepress; then
          echo "✅ Repository cloned successfully"
          echo "📁 Cloned repository contents:"
          ls -la docs-vitepress/ | head -10
        else
          echo "❌ Failed to clone repository"
          echo "🔍 Testing SSH connection to GitHub:"
          ssh -T git@github.com || echo "SSH connection test failed"
          exit 1
        fi
        
        # Verify source directory exists
        if [ ! -d "converted_docs" ]; then
          echo "❌ ERROR: converted_docs directory not found"
          exit 1
        fi
        
        echo "📋 Files available for deployment:"
        ls -la converted_docs/
        
        targetDir="docs-vitepress/docs/components"
        mkdir -p "$targetDir"
        echo "📁 Created target directory: $targetDir"
        
        filesCopied=0
        filesSkipped=0
        echo "🔄 Starting file copy process..."
        
        while IFS= read -r file; do
          src="converted_docs/${file}"
          if [ -f "$src" ]; then
            if cp "$src" "$targetDir/"; then
              echo "  ✅ Copied: ${file} ($(stat -c%s "$src" 2>/dev/null || echo '?') bytes)"
              filesCopied=$((filesCopied+1))
            else
              echo "  ❌ Failed to copy: ${file}"
              filesSkipped=$((filesSkipped+1))
            fi
          else
            echo "  ⚠️  Skipped (not a file): ${file}"
            filesSkipped=$((filesSkipped+1))
          fi
        done < <(ls converted_docs 2>/dev/null || echo "")
        
        echo "📊 Copy summary: $filesCopied files copied, $filesSkipped files skipped"
        
        if [ $filesCopied -eq 0 ]; then
          echo "⚠️  WARNING: No files were copied to target repository"
        fi
        
        # Push changes
        pushd docs-vitepress >/dev/null
        git config user.name "Docs CI Bot"
        git config user.email "docs-bot@ecoos.dev"
        git add docs/components/
        # Copy state file to target repository with validation
        if [ -f "../new-state.json" ]; then
          echo "📄 Copying conversion state to target repository"
          
          # Validate state file before copying
          if python3 -c "import json; json.load(open('../new-state.json'))" 2>/dev/null; then
            cp ../new-state.json .conversion-state.json
            echo "✅ State file copied and validated"
            echo "📊 New state file size: $(stat -c%s .conversion-state.json) bytes"
            git add .conversion-state.json
          else
            echo "❌ State file validation failed, not copying corrupted state"
            # Keep existing state file if new one is corrupted
            if [ -f ".conversion-state.json" ]; then
              echo "ℹ️  Keeping existing state file"
            fi
          fi
        else
          echo "⚠️  No new state file found, state will not be updated"
          # This is an edge case that shouldn't happen if update-state step succeeded
        fi
        
        # Check for changes and commit
        echo "🔍 Checking for changes in target repository..."
        git status --porcelain docs/components/ .conversion-state.json
        
        if ! git diff --staged --quiet; then
          sha="${GITHUB_SHA:-unknown-sha}"
          echo "✅ Changes detected, committing and pushing..."
          echo "📝 Commit message: Auto-update docs from ${sha}"
          git commit -m "Auto-update docs from ${sha}"
          
          if git push origin HEAD:main; then
            echo "🚀 Successfully pushed to docs-vitepress repository"
          else
            echo "❌ Failed to push to target repository"
            exit 1
          fi
        else
          echo "ℹ️  No changes to commit - files may already be up to date"
        fi
        popd >/dev/null
        echo "=== DEPLOYMENT COMPLETE ==="
  
    - name: Generate and update components manifest
      id: manifest
      if: steps.changed-files.outputs.any_changed == 'true'
      env:
        TARGET_REPO_SSH_KEY: ${{ secrets.VITEPRESS_DEPLOY_TOKEN }}
      shell: bash
      run: |
        set -eo pipefail
        echo "=== MANIFEST GENERATION START ==="
        echo "📄 Generating components manifest for updated documentation"
        
        pushd docs-vitepress >/dev/null
        
        # Check if package.json exists and is valid
        if [ ! -f "package.json" ]; then
          echo "⚠️  No package.json found in target repository, skipping manifest generation"
          echo "This is normal if the target repository doesn't use npm-based manifest generation"
          popd >/dev/null
          exit 0
        fi
        echo "✅ Found package.json in target repository"
        
        # Validate JSON syntax
        if ! python3 -m json.tool package.json >/dev/null 2>&1; then
          echo "❌ Invalid package.json syntax, skipping manifest generation"
          echo "🔍 First few lines of package.json:"
          head -5 package.json || echo "Cannot read package.json"
          popd >/dev/null
          exit 0
        fi
        echo "✅ package.json syntax is valid"
        
        # Check if the required script exists
        if ! grep -q '"docs:generate-components"' package.json; then
          echo "⚠️  docs:generate-components script not found in package.json"
          echo "Available scripts:"
          grep -A 10 '"scripts"' package.json | head -15 || echo "No scripts section found"
          echo "Skipping manifest generation"
          popd >/dev/null
          exit 0
        fi
        echo "✅ Found docs:generate-components script"
        
        echo "📦 Installing dependencies..."
        if npm ci 2>/dev/null; then
          echo "✅ Dependencies installed successfully using npm ci"
        elif npm install 2>/dev/null; then
          echo "✅ Dependencies installed successfully using npm install"
        else
          echo "❌ Failed to install dependencies"
          echo "🔍 npm version: $(npm --version 2>/dev/null || echo 'not available')"
          echo "🔍 node version: $(node --version 2>/dev/null || echo 'not available')"
          echo "Skipping manifest generation"
          popd >/dev/null
          exit 0
        fi
        
        echo "🔄 Generating components manifest..."
        if npm run docs:generate-components; then
          echo "✅ Manifest generation completed successfully"
        else
          echo "❌ Failed to generate manifest"
          echo "🔍 Checking for existing manifest file:"
          ls -la .vitepress/components.json 2>/dev/null || echo "No existing manifest found"
          echo "Continuing without manifest update"
          popd >/dev/null
          exit 0
        fi
        
        # Setup SSH and push if manifest was generated
        if [ -f ".vitepress/components.json" ]; then
          echo "✅ Manifest file generated: .vitepress/components.json"
          echo "📊 Manifest file size: $(stat -c%s .vitepress/components.json 2>/dev/null || echo 'unknown') bytes"
          
          mkdir -p ~/.ssh
          ssh-keyscan -t ed25519,rsa github.com >> ~/.ssh/known_hosts
          eval "$(ssh-agent -s)"
          ssh-add - <<< "$TARGET_REPO_SSH_KEY"
          
          git add .vitepress/components.json
          if ! git diff --staged --quiet; then
            echo "📝 Committing manifest changes..."
            git config user.name "Docs CI Bot"
            git config user.email "docs-bot@ecoos.dev"
            git commit -m "Auto-update components manifest from ${GITHUB_SHA:-unknown-sha}"
            
            if git push origin HEAD:main; then
              echo "🚀 Successfully pushed manifest update"
            else
              echo "❌ Failed to push manifest update"
            fi
          else
            echo "ℹ️  No manifest changes to commit (manifest unchanged)"
          fi
        else
          echo "⚠️  No manifest file found after generation"
        fi
        
        popd >/dev/null
        echo "=== MANIFEST GENERATION COMPLETE ==="

    - name: Update Conversion State
      id: update-state
      if: steps.changed-files.outputs.any_changed == 'true'
      run: |
        echo "=== UPDATING CONVERSION STATE ==="
        
        # Create new state with corrected logic
        python3 << 'EOF'
import json
import os
from datetime import datetime

# Load current state
try:
    with open('current-state.json') as f:
        state = json.load(f)
except:
    state = {}

# Initialize state structure
if 'failedFiles' not in state:
    state['failedFiles'] = {}

# Get current info
current_commit = os.environ.get('GITHUB_SHA', '')
current_time = datetime.utcnow().isoformat() + 'Z'
processed_files = [f.strip() for f in os.environ.get('PROCESSED_FILES', '').split() if f.strip()]
failed_files = [f.strip() for f in os.environ.get('FAILED_FILES', '').split() if f.strip()]

# IMPORTANT: successfulFiles contains ONLY current session files
# This replaces any previous successful files from earlier sessions
successful_files_current_session = {}
for file_path in processed_files:
    if file_path and file_path not in failed_files:
        # Remove from failed files if it was previously failed (now successful)
        if file_path in state['failedFiles']:
            del state['failedFiles'][file_path]
            print(f"Moved {file_path} from failed to successful")
        
        # Add to current session successful files
        successful_files_current_session[file_path] = {
            'convertedAt': current_time,
            'sourceCommit': current_commit,
            'sourceHash': 'sha256-placeholder'  # TODO: implement actual hash
        }

# Update failed files (cumulative - keep existing failures)
for file_path in failed_files:
    if file_path:
        if file_path in state['failedFiles']:
            # Increment attempt count for existing failed file
            state['failedFiles'][file_path]['attemptCount'] += 1
            print(f"Incremented attempt count for {file_path} to {state['failedFiles'][file_path]['attemptCount']}")
        else:
            # New failed file
            state['failedFiles'][file_path] = {
                'attemptCount': 1
            }
            print(f"Added new failed file: {file_path}")
        
        # Update failure details
        state['failedFiles'][file_path].update({
            'lastAttempt': current_time,
            'lastError': 'conversion failed',
            'sourceCommit': current_commit
        })

# Set successful files to ONLY current session (not cumulative)
state['successfulFiles'] = successful_files_current_session

# Update global state
state['lastProcessedCommit'] = current_commit
state['lastSuccessfulRun'] = current_time

# Save state
with open('new-state.json', 'w') as f:
    json.dump(state, f, indent=2)

print(f"✅ State updated:")
print(f"  - Current session successful: {len(successful_files_current_session)}")
print(f"  - Total cumulative failed: {len(state['failedFiles'])}")
print(f"  - Last processed commit: {current_commit[:8]}...")
EOF
        
        echo "📊 New state file created:"
        ls -la new-state.json
        echo "📄 State summary:"
        python3 -c "
import json
with open('new-state.json') as f:
    state = json.load(f)
print(f'Successful files: {len(state.get(\"successfulFiles\", {}))}')
print(f'Failed files: {len(state.get(\"failedFiles\", {}))}')
print(f'Last commit: {state.get(\"lastProcessedCommit\", \"none\")}')
"
        echo "=== STATE UPDATE COMPLETE ==="

    - name: Workflow Summary
      if: always()
      run: |
        echo "=== WORKFLOW EXECUTION SUMMARY ==="
        echo "📅 Execution date: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
        echo "🌐 Repository: ${{ github.repository }}"
        echo "🔗 Commit: ${{ github.sha }}"
        echo "🏃 Triggered by: ${{ github.event_name }}"
        echo "🕰️ Workflow run ID: ${{ github.run_id }}"
        
        # Check step outcomes
        echo "🔍 Step execution status:"
        echo "  - LibreOffice installation: ${{ steps.install-libreoffice.outcome || 'not executed' }}"
        echo "  - Git state debug: ${{ steps.debug-git.outcome || 'not executed' }}"
        echo "  - Change detection: ${{ steps.changed-files.outcome || 'not executed' }}"
        echo "  - Conversion: ${{ steps.convert.outcome || 'skipped' }}"
        echo "  - Deployment: ${{ steps.deploy.outcome || 'skipped' }}"
        echo "  - Manifest generation: ${{ steps.manifest.outcome || 'skipped' }}"
        
        # Overall workflow status
        if [ "${{ job.status }}" == "success" ]; then
          echo "✅ WORKFLOW STATUS: SUCCESS"
        elif [ "${{ job.status }}" == "failure" ]; then
          echo "❌ WORKFLOW STATUS: FAILED"
          echo "🔍 Check the failed steps above for error details"
        elif [ "${{ job.status }}" == "cancelled" ]; then
          echo "⚠️  WORKFLOW STATUS: CANCELLED"
        else
          echo "🔄 WORKFLOW STATUS: ${{ job.status }}"
        fi
        
        # File processing summary
        if [ "${{ steps.changed-files.outputs.any_changed }}" == "true" ]; then
          echo "🟢 PROCESSING RESULT: CHANGES DETECTED AND PROCESSED"
          echo "📄 Files in scope: $(echo '${{ steps.changed-files.outputs.all_changed_files }}' | wc -w)"
          echo "🎯 Target repository: peerf-eco/docs-vitepress"
          
          # State tracking summary
          if [ -f "new-state.json" ]; then
            echo "📄 State tracking summary:"
            python3 -c "
import json
try:
    with open('new-state.json') as f:
        state = json.load(f)
    print(f'  - Total successful files: {len(state.get(\"successfulFiles\", {}))}')
    print(f'  - Total failed files: {len(state.get(\"failedFiles\", {}))}')
    print(f'  - Last processed commit: {state.get(\"lastProcessedCommit\", \"none\")[:8]}...')
except Exception as e:
    print(f'  - State file error: {e}')
" 2>/dev/null || echo "  - State information unavailable"
          fi
          
          # Check if conversion actually succeeded
          if [ "${{ steps.convert.outcome }}" == "success" ]; then
            echo "✅ Conversion completed successfully"
          elif [ "${{ steps.convert.outcome }}" == "failure" ]; then
            echo "❌ Conversion failed - check conversion logs"
          fi
          
          # Check if deployment succeeded
          if [ "${{ steps.deploy.outcome }}" == "success" ]; then
            echo "✅ Deployment completed successfully"
          elif [ "${{ steps.deploy.outcome }}" == "failure" ]; then
            echo "❌ Deployment failed - check deployment logs"
          fi
          
          # Check if state update succeeded
          if [ "${{ steps.update-state.outcome }}" == "success" ]; then
            echo "✅ State tracking updated successfully"
          elif [ "${{ steps.update-state.outcome }}" == "failure" ]; then
            echo "❌ State tracking update failed"
          fi
        else
          echo "🟡 PROCESSING RESULT: NO CHANGES DETECTED"
          echo "📄 Files processed: 0"
          echo "🎯 Target repository: No updates needed"
          
          # Show current state even when no changes
          if [ -f "current-state.json" ]; then
            echo "📄 Current state summary:"
            python3 -c "
import json
try:
    with open('current-state.json') as f:
        state = json.load(f)
    print(f'  - Total successful files: {len(state.get(\"successfulFiles\", {}))}')
    print(f'  - Total failed files: {len(state.get(\"failedFiles\", {}))}')
    print(f'  - Last processed commit: {state.get(\"lastProcessedCommit\", \"none\")[:8] if state.get(\"lastProcessedCommit\") else \"none\"}...')
except Exception as e:
    print(f'  - State file error: {e}')
" 2>/dev/null || echo "  - No state information available"
          fi
        fi
        
        # Troubleshooting guidance
        if [ "${{ job.status }}" != "success" ]; then
          echo ""
          echo "🔧 TROUBLESHOOTING GUIDANCE:"
          echo "  1. Check the step-by-step logs above for specific error messages"
          echo "  2. Look for ❌ (error) and ⚠️ (warning) indicators in the logs"
          echo "  3. Verify that .fodt files exist in the components/ directory"
          echo "  4. Ensure SSH keys and repository permissions are correct"
          echo "  5. Check if LibreOffice and DocExport extension installed properly"
        fi
        
        echo "🔍 For detailed logs, check the individual step outputs above"
        echo "=== END WORKFLOW SUMMARY ==="
